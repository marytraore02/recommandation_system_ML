# Worker ARQ pour Analytics - Documentation

## üìã Vue d'ensemble

Ce syst√®me ex√©cute automatiquement les analyses de popularit√© et tendances toutes les 24 heures via ARQ (Asynchronous Redis Queue).

### Cycle journalier :
- **Popularit√©** : Calcul bas√© sur les √©v√©nements des derni√®res 24 heures
- **Tendances** : Comparaison entre les 24h r√©centes et les 48h pr√©c√©dentes

## üîß Installation

### 1. Installer ARQ

```bash
pip install arq
```

### 2. V√©rifier les d√©pendances existantes

Assurez-vous que vous avez d√©j√† :
- `redis`
- `clickhouse-driver`
- `python-dotenv`

## üìÅ Structure des fichiers

```
votre_projet/
‚îú‚îÄ‚îÄ worker_analytics.py              # Worker ARQ principal
‚îú‚îÄ‚îÄ trigger_analytics_manually.py    # Script pour test manuel
‚îú‚îÄ‚îÄ start_analytics_worker.sh        # Script de d√©marrage
‚îî‚îÄ‚îÄ .env                             # Variables d'environnement
```

## ‚öôÔ∏è Configuration

### Variables d'environnement (.env)

```env
# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# ClickHouse
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT2=9000
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=
CLICKHOUSE_DATABASE=analytics

# Configuration Analytics (dans utils/config.py)
TABLE_NAME=user_events
```

## üöÄ Utilisation

### D√©marrer le worker (Production)

```bash
# Option 1: Directement avec arq
arq worker_analytics.WorkerSettings

# Option 2: Avec le script bash
chmod +x start_analytics_worker.sh
./start_analytics_worker.sh

# Option 3: Avec plus de logs (mode verbose)
arq worker_analytics.WorkerSettings --verbose
```

### Tester manuellement (sans attendre le cron)

```bash
# Ex√©cuter l'analyse imm√©diatement
python trigger_analytics_manually.py

# Ou tester directement le worker
python worker_analytics.py
```

## ‚è∞ Planification

La t√¢che est configur√©e pour s'ex√©cuter :
- **Tous les jours √† 2h00 du matin**
- **Au d√©marrage** (premi√®re ex√©cution imm√©diate avec `run_at_startup=True`)

Pour modifier l'horaire, √©ditez dans `worker_analytics.py` :

```python
cron_jobs = [
    cron(run_analytics_task, hour=2, minute=0, run_at_startup=True)
    # Exemples d'autres planifications:
    # cron(run_analytics_task, hour=0, minute=0)  # Minuit
    # cron(run_analytics_task, hour={6, 18}, minute=0)  # 6h et 18h
    # cron(run_analytics_task, minute=0)  # Toutes les heures
]
```

## üìä R√©sultats stock√©s dans Redis

Les cl√©s Redis cr√©√©es :

```
analytics_popularity_by_country       # Popularit√© par pays (expire apr√®s 25h)
analytics_popularity_by_category      # Popularit√© par cat√©gorie
analytics_trending_by_country         # Tendances par pays
analytics_trending_by_category        # Tendances par cat√©gorie
comprehensive_analytics_metadata      # M√©tadonn√©es de l'analyse
```

Expiration : **25 heures** (marge de s√©curit√© de 1h)

## üîç Monitoring et Logs

### Consulter les logs du worker

Le worker affiche des logs d√©taill√©s :

```
[timestamp] INFO - üöÄ D√©marrage de l'analyse analytics planifi√©e
[timestamp] INFO - ‚¨áÔ∏è Chargement des √©v√©nements des 3 derniers jours depuis ClickHouse...
[timestamp] INFO - üìÅ 1234 √©v√©nements charg√©s depuis ClickHouse.
[timestamp] INFO - üåç Calcul de la popularit√© par pays (24h)...
[timestamp] INFO - üìÇ Calcul de la popularit√© par cat√©gorie (24h)...
[timestamp] INFO - üìà Calcul des tendances par pays (24h vs 48h)...
[timestamp] INFO - üìä Calcul des tendances par cat√©gorie (24h vs 48h)...
[timestamp] INFO - ‚úÖ R√©sultats stock√©s dans Redis
[timestamp] INFO - ‚úÖ Analyse analytics termin√©e avec succ√®s
```

### V√©rifier l'√©tat du worker ARQ

```bash
# Depuis Redis CLI
redis-cli

> KEYS arq:*
> HGETALL arq:job:[job_id]
```

### Consulter les r√©sultats dans Redis

```python
import redis
import json

r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

# Voir la popularit√© par pays
data = json.loads(r.get('analytics_popularity_by_country'))
print(data)

# Voir les m√©tadonn√©es
metadata = json.loads(r.get('comprehensive_analytics_metadata'))
print(f"Derni√®re analyse: {metadata['last_analysis']}")
```

## üê≥ D√©ploiement avec Docker (optionnel)

### Dockerfile pour le worker

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["arq", "worker_analytics.WorkerSettings"]
```

### docker-compose.yml

```yaml
services:
  analytics-worker:
    build: .
    container_name: analytics_worker
    env_file: .env
    depends_on:
      - redis
      - clickhouse
    restart: always
    volumes:
      - ./logs:/app/logs
```

## üîÑ Gestion du processus (Production)

### Avec systemd

Cr√©er `/etc/systemd/system/analytics-worker.service` :

```ini
[Unit]
Description=Analytics Worker ARQ
After=network.target redis.service

[Service]
Type=simple
User=your_user
WorkingDirectory=/path/to/your/project
ExecStart=/path/to/venv/bin/arq worker_analytics.WorkerSettings
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Activer et d√©marrer :

```bash
sudo systemctl enable analytics-worker
sudo systemctl start analytics-worker
sudo systemctl status analytics-worker

# Voir les logs
sudo journalctl -u analytics-worker -f
```

### Avec Supervisor

Configuration dans `/etc/supervisor/conf.d/analytics-worker.conf` :

```ini
[program:analytics-worker]
command=/path/to/venv/bin/arq worker_analytics.WorkerSettings
directory=/path/to/your/project
user=your_user
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/analytics-worker.log
```

```bash
sudo supervisorctl reread
sudo supervisorctl update
sudo supervisorctl start analytics-worker
```

## üß™ Tests et Debugging

### Test complet du syst√®me

```bash
# 1. V√©rifier la connexion ClickHouse
python -c "from clickhouse_driver import Client; c = Client(host='localhost'); print(c.execute('SELECT 1'))"

# 2. V√©rifier la connexion Redis
redis-cli ping

# 3. Tester le worker directement
python worker_analytics.py

# 4. D√©clencher manuellement via ARQ
python trigger_analytics_manually.py
```

### D√©boguer les erreurs

Si le worker ne d√©marre pas :

1. **V√©rifier les variables d'environnement**
   ```bash
   python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('REDIS_HOST'))"
   ```

2. **V√©rifier les connexions**
   ```bash
   # Redis
   redis-cli ping
   
   # ClickHouse
   echo "SELECT 1" | clickhouse-client
   ```

3. **Regarder les logs d√©taill√©s**
   ```bash
   arq worker_analytics.WorkerSettings --verbose
   ```

## üìà Personnalisation

### Modifier les poids des √©v√©nements

Dans `worker_analytics.py` :

```python
self.event_weights = {
    "video_view": 1.0,
    "video_share": 5.0,  # Augmenter l'importance des partages
    "video_favorite": 3.0,
    "video_replay": 2.0,
    "video_skip": -1.0,  # P√©naliser plus les skips
    "cagnotte_detail_view": 1.5
}
```

### Modifier la d√©croissance temporelle

```python
self.time_decay_days = 2  # Au lieu de 1 jour
```

### Changer la fr√©quence d'ex√©cution

```python
# Toutes les 12 heures
cron_jobs = [
    cron(run_analytics_task, hour={0, 12}, minute=0)
]

# Toutes les 6 heures
cron_jobs = [
    cron(run_analytics_task, hour={0, 6, 12, 18}, minute=0)
]
```

## ‚ùì FAQ

**Q: Comment arr√™ter le worker ?**
```bash
# Si d√©marr√© manuellement : Ctrl+C
# Avec systemd : sudo systemctl stop analytics-worker
# Avec supervisor : sudo supervisorctl stop analytics-worker
```

**Q: Comment voir si la t√¢che s'est bien ex√©cut√©e ?**
```bash
# V√©rifier les logs
tail -f /var/log/analytics-worker.log

# V√©rifier dans Redis
redis-cli GET comprehensive_analytics_metadata
```

**Q: Que faire si une analyse √©choue ?**

Le worker ARQ r√©essaiera automatiquement. Consultez les logs pour identifier l'erreur. Les causes fr√©quentes :
- Connexion ClickHouse perdue
- Redis inaccessible
- Pas de donn√©es dans la p√©riode

**Q: Peut-on ex√©cuter plusieurs workers ?**

Oui ! ARQ supporte plusieurs workers pour la scalabilit√© :
```bash
# Terminal 1
arq worker_analytics.WorkerSettings

# Terminal 2
arq worker_analytics.WorkerSettings
```

## üîí S√©curit√©

- Les mots de passe Redis/ClickHouse doivent √™tre dans `.env` (jamais committ√©)
- Utiliser des connexions chiffr√©es en production
- Limiter les permissions Redis aux cl√©s n√©cessaires
- Configurer un timeout appropri√© pour √©viter les jobs bloqu√©s

## üìû Support

En cas de probl√®me :
1. V√©rifier les logs du worker
2. Tester manuellement avec `trigger_analytics_manually.py`
3. V√©rifier les connexions Redis/ClickHouse
4. Consulter la documentation ARQ : https://arq-docs.helpmanual.io/